import streamlit as st
import pandas as pd
import os
import json
import zipfile
import logging
import glob
from pygwalker.api.streamlit import StreamlitRenderer
# --- åŸºæœ¬è¨­å®š ---
logging.basicConfig(level=logging.INFO)
st.set_page_config(page_title="Kaggle åˆ†æå·¥å…·", layout="wide")
BASE_DIR = st.session_state.get('BASE_DIR', os.path.dirname(os.path.abspath(__file__)))

# --- èªè­‰å‡½æ•¸ ---
@st.cache_resource
def init_kaggle_api():
    local_kaggle_path = "kaggle.json"
    if os.path.exists(os.path.join(BASE_DIR, local_kaggle_path)):
        try:
            with open(os.path.join(BASE_DIR, local_kaggle_path), 'r') as f:
                credentials = json.load(f)
            os.environ['KAGGLE_USERNAME'] = credentials['username']
            os.environ['KAGGLE_KEY'] = credentials['key']
        except Exception as e:
            st.error(f"è®€å–æœ¬åœ° `kaggle.json` æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            st.session_state['api_authenticated'] = False
            return None

    try:
        from kaggle.api.kaggle_api_extended import KaggleApi
        api = KaggleApi()
        api.authenticate()
        st.session_state['api_authenticated'] = True
        return api
    except Exception as e:
        st.error(f"Kaggle API èªè­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ‚¨çš„æ†‘è­‰è¨­å®šã€‚")
        st.session_state['api_authenticated'] = False
        return None

def code_finder_page(api):
    st.title("ğŸ” å°‹æ‰¾ç›¸é—œç¨‹å¼ç¢¼ (Kernels)")
    st.info("æ‚¨å¯ä»¥è¼¸å…¥ä¸€å€‹è³‡æ–™é›†çš„ Refï¼Œä¾†å°‹æ‰¾å…¶ä»–é–‹ç™¼è€…æ˜¯å¦‚ä½•åˆ†æé€™å€‹è³‡æ–™é›†çš„ã€‚")

    # --- æ­¥é©Ÿä¸€ï¼šè¼¸å…¥è³‡æ–™é›† Refï¼Œå°‹æ‰¾ç›¸é—œç¨‹å¼ç¢¼ ---
    st.subheader("æ­¥é©Ÿä¸€ï¼šè¼¸å…¥è³‡æ–™é›† Refï¼Œå°‹æ‰¾ç›¸é—œç¨‹å¼ç¢¼")
    dataset_ref = st.text_input(
        "è¼¸å…¥è³‡æ–™é›† Refï¼š", 
        placeholder="ä¾‹å¦‚: harshsingh2209/supply-chain-analysis",
        key="code_finder_dataset_ref"
    )
    st.caption("èªªæ˜ï¼šè¼¸å…¥è³‡æ–™é›†çš„ Refï¼ˆå¦‚ 'username/dataset-name'ï¼‰ï¼Œå¯å¾ Kaggle API å·¥å…·é é¢è¤‡è£½ã€‚")
    if st.button("å°‹æ‰¾ç¨‹å¼ç¢¼", key="find_kernels_button"):
        st.caption("èªªæ˜ï¼šé»æ“Šå¾Œï¼Œç³»çµ±å°‡é¡¯ç¤ºèˆ‡è©²è³‡æ–™é›†ç›¸é—œçš„ç¨‹å¼ç¢¼æ¸…å–®ï¼ˆKaggle Kernelsï¼‰ã€‚")
        if dataset_ref:
            st.session_state.current_dataset_ref = dataset_ref  # æ–°å¢ï¼šå„²å­˜ç•¶å‰è³‡æ–™é›† Refï¼Œç”¨æ–¼å¾ŒçºŒè·¯å¾‘
            with st.spinner(f"æ­£åœ¨å°‹æ‰¾èˆ‡ '{dataset_ref}' ç›¸é—œçš„ç¨‹å¼ç¢¼..."):
                try:
                    kernels = api.kernels_list(dataset=dataset_ref, sort_by='hotness', page_size=50)
                    if kernels:
                        kernel_data = [{
                            'Ref': k.ref,
                            'Title': k.title,
                            'Author': k.author,
                        } for k in kernels]
                        st.session_state.kernels_df = pd.DataFrame(kernel_data)
                    else:
                        st.warning("æ‰¾ä¸åˆ°èˆ‡æ­¤è³‡æ–™é›†ç›¸é—œçš„ç¨‹å¼ç¢¼ã€‚")
                        st.session_state.kernels_df = pd.DataFrame()
                except Exception as e:
                    st.error(f"å°‹æ‰¾ç¨‹å¼ç¢¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        else:
            st.warning("è«‹å…ˆè¼¸å…¥è³‡æ–™é›† Refã€‚")
    
    if 'kernels_df' in st.session_state and not st.session_state.kernels_df.empty:
        st.dataframe(st.session_state.kernels_df, use_container_width=True)
        
        # --- æ­¥é©ŸäºŒï¼šä¸‹è¼‰ Kernel ---
        st.markdown("---")
        st.subheader("æ­¥é©ŸäºŒï¼šå¾ä¸Šæ–¹çµæœè¤‡è£½ Refï¼Œä¸‹è¼‰ç¨‹å¼ç¢¼")
        kernel_ref_to_download = st.text_input(
            "è¼¸å…¥ç¨‹å¼ç¢¼ Refï¼š",
            placeholder="ä¾‹å¦‚: some-user/awesome-analysis-notebook",
            key="kernel_ref_to_download"
        )
        st.caption("èªªæ˜ï¼šRef æ˜¯ç¨‹å¼ç¢¼çš„å”¯ä¸€è­˜åˆ¥ç¢¼ï¼Œæ ¼å¼å¦‚ 'username/kernel-name'ï¼Œå¯å¾ä¸Šæ–¹è¡¨æ ¼è¤‡è£½ã€‚")
        if st.button("ä¸‹è¼‰ç¨‹å¼ç¢¼ (.ipynb)", key="download_kernel_button"):
            st.caption("èªªæ˜ï¼šé»æ“Šå¾Œï¼Œç¨‹å¼ç¢¼å°‡ä¸‹è¼‰ç‚º .ipynb æª”æ¡ˆè‡³ 'kaggle_downloads/{dataset_ref}/kernels' è³‡æ–™å¤¾ã€‚")
            if kernel_ref_to_download and 'current_dataset_ref' in st.session_state:
                base_path = 'kaggle_downloads'
                dataset_path = os.path.join(base_path, st.session_state.current_dataset_ref)
                kernel_download_path = os.path.join(dataset_path, 'kernels')  # æ–°å¢ï¼škernels å­è³‡æ–™å¤¾
                os.makedirs(kernel_download_path, exist_ok=True)
                with st.spinner(f"æ­£åœ¨ä¸‹è¼‰ '{kernel_ref_to_download}'..."):
                    try:
                        api.kernels_pull(kernel_ref_to_download, path=kernel_download_path)
                        st.success(f"ç¨‹å¼ç¢¼ '{kernel_ref_to_download}.ipynb' å·²æˆåŠŸä¸‹è¼‰åˆ° `{kernel_download_path}` è³‡æ–™å¤¾ï¼")
                        
                        # æ–°å¢ï¼šæ­¥é©Ÿä¸‰ - é¸æ“‡ç¨‹å¼ç¢¼ä¸¦å°å‘ Colab
                        st.markdown("---")
                        st.subheader("æ­¥é©Ÿä¸‰ï¼šé‹è¡Œç¨‹å¼ç¢¼åœ¨ Google Colab")
                        # åˆ—å‡º kernels è³‡æ–™å¤¾ä¸‹çš„ .ipynb æª”æ¡ˆ
                        ipynb_files = glob.glob(os.path.join(kernel_download_path, '*.ipynb'))
                        if ipynb_files:
                            display_files = [os.path.basename(f) for f in ipynb_files]  # åªé¡¯ç¤ºæª”å
                            selected_ipynb = st.selectbox("é¸æ“‡ä¸€å€‹å·²ä¸‹è¼‰çš„ç¨‹å¼ç¢¼æª”æ¡ˆé‹è¡Œï¼š", display_files, key="selected_kernel_file")
                            st.caption("èªªæ˜ï¼šé¸æ“‡æª”æ¡ˆå¾Œï¼Œé»æ“Šä¸‹æ–¹æŒ‰éˆ•é–‹å•Ÿ Colabï¼Œä¸¦ä¸Šå‚³è©²æª”æ¡ˆé‹è¡Œå­¸ç¿’æ•¸æ“šåˆ†æã€‚")
                            if selected_ipynb:
                                selected_path = os.path.join(kernel_download_path, selected_ipynb)
                                st.info(f"""
                                æ‚¨é¸æ“‡äº† '{selected_ipynb}'ï¼ç¾åœ¨å¯ä»¥å°‡å®ƒä¸Šå‚³åˆ° Google Colab é‹è¡Œã€‚
                                
                                **æ­¥é©ŸæŒ‡å—ï¼š**
                                1. é»æ“Šä¸‹æ–¹æŒ‰éˆ•é–‹å•Ÿ Google Colabï¼ˆæ–°åˆ†é ï¼‰ã€‚
                                2. åœ¨ Colab ä»‹é¢ï¼Œé¸æ“‡ã€Œæª”æ¡ˆ > ä¸Šå‚³ç­†è¨˜æœ¬ã€æˆ–ç›´æ¥æ‹–æ›³ '{selected_ipynb}' æª”æ¡ˆä¸Šå‚³ï¼ˆæª”æ¡ˆä½æ–¼ {selected_path}ï¼‰ã€‚
                                3. ä¸Šå‚³å¾Œï¼Œå³å¯ç·¨è¼¯ã€é‹è¡Œç¨‹å¼ç¢¼ï¼ˆColab æ”¯æ´ GPU/TPUï¼Œé©åˆå­¸ç¿’ ML æ¨¡å‹ï¼‰ã€‚
                                4. å¦‚æœç¨‹å¼ç¢¼éœ€è¦ Kaggle è³‡æ–™é›†ï¼Œå¯åœ¨ Colab ä¸­ä½¿ç”¨ Kaggle API é‡æ–°ä¸‹è¼‰ï¼ˆé¡ä¼¼æœ¬ç¨‹å¼èªè­‰æ­¥é©Ÿï¼‰ã€‚
                                
                                **æç¤ºï¼š** Colab æ˜¯å…è²»çš„é›²ç«¯ Jupyter Notebookï¼Œé©åˆåˆå­¸è€…ç·´ç¿’æ•¸æ“šåˆ†æã€‚
                                """)
                                st.link_button("é–‹å•Ÿ Google Colab ä¸¦ä¸Šå‚³æª”æ¡ˆ", "https://colab.research.google.com/", help="é»æ“Šé–‹å•Ÿ Colab æ–°åˆ†é ")
                        else:
                            st.warning("kernels è³‡æ–™å¤¾ä¸­å°šæœªæœ‰ .ipynb æª”æ¡ˆï¼Œè«‹å…ˆä¸‹è¼‰ã€‚")
                    except Exception as e:
                        st.error(f"ä¸‹è¼‰ç¨‹å¼ç¢¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            else:
                st.warning("è«‹å…ˆè¼¸å…¥è¦ä¸‹è¼‰çš„ç¨‹å¼ç¢¼ Refï¼Œæˆ–ç¢ºèªå·²è¼¸å…¥è³‡æ–™é›† Refã€‚")

# --- ä¸»ä»‹é¢ï¼šKaggle API åŠŸèƒ½ ---
def main_page(api):
    st.title("Kaggle api")
    st.subheader("æ¢ç´¢ç†±é–€è³‡æ–™é›†")
    
    DATASET_CATEGORIES = {
        "--- è«‹é¸æ“‡ä¸€å€‹æ¢ç´¢åˆ†é¡ ---": "",
        "å¥åº·èˆ‡é†«ç™‚ (Health & Medical)": "health medical",
        "é‡‘èèˆ‡ç¶“æ¿Ÿ (Finance & Economics)": "finance economics",
        "é›»è…¦è¦–è¦º (Computer Vision)": "computer vision images",
        "è‡ªç„¶èªè¨€è™•ç† (NLP)": "nlp text data",
        "æ°£å€™èˆ‡ç’°å¢ƒ (Climate & Environment)": "climate environment",
        "æ•™è‚² (Education)": "education",
        "ç¤¾ç¾¤åª’é«” (Social Media)": "social media"
    }

    def fetch_trending_datasets():
        selected_cat_name = st.session_state.category_selector
        if selected_cat_name == list(DATASET_CATEGORIES.keys())[0]:
            st.session_state.trending_datasets_df = pd.DataFrame()
            return
        search_term = DATASET_CATEGORIES[selected_cat_name]
        with st.spinner(f"æ­£åœ¨æ“·å– '{selected_cat_name}' åˆ†é¡çš„ç†±é–€è³‡æ–™é›†..."):
            try:
                datasets = api.dataset_list(search=search_term, sort_by='hottest')
                if datasets:
                    datasets = datasets[:10]
                    dataset_data = [{'Ref': d.ref, 'Title': d.title, 'URL': f"https://www.kaggle.com/{d.ref}"} for d in datasets]
                    st.session_state.trending_datasets_df = pd.DataFrame(dataset_data)
                else:
                    st.session_state.trending_datasets_df = pd.DataFrame()
            except Exception as e:
                st.error(f"æ“·å–ç†±é–€è³‡æ–™é›†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                st.session_state.trending_datasets_df = pd.DataFrame()

    st.selectbox(
        "é¸æ“‡ä¸€å€‹åˆ†é¡ï¼Œç«‹å³æŸ¥çœ‹è©²é ˜åŸŸæœ€ç†±é–€çš„å‰10å€‹è³‡æ–™é›†ï¼š",
        options=list(DATASET_CATEGORIES.keys()),
        key="category_selector",
        on_change=fetch_trending_datasets
    )
    st.caption("èªªæ˜ï¼šé¸æ“‡åˆ†é¡å¾Œï¼Œç³»çµ±æœƒé¡¯ç¤ºè©²é ˜åŸŸæœ€ç†±é–€çš„å‰10å€‹è³‡æ–™é›†ï¼Œé»æ“Šè¡¨æ ¼ä¸­çš„é€£çµå¯å‰å¾€ Kaggle æŸ¥çœ‹è©³æƒ…ã€‚")
    
    if 'trending_datasets_df' in st.session_state and not st.session_state.trending_datasets_df.empty:
        st.subheader(f"ğŸ“ˆ '{st.session_state.category_selector}' åˆ†é¡ä¸‹çš„ç†±é–€è³‡æ–™é›†")
        st.data_editor(
            st.session_state.trending_datasets_df,
            column_config={"URL": st.column_config.LinkColumn("Kaggle é€£çµ", display_text="ğŸ”— å‰å¾€")},
            hide_index=True,
            use_container_width=True
        )

    st.markdown("---")
    with st.expander("ğŸ” æ‰‹å‹•æœå°‹ (é»æ­¤å±•é–‹)"):
        with st.form(key="dataset_search_form"):
            manual_search_term = st.text_input("è¼¸å…¥é—œéµå­—é€²è¡Œç²¾æº–æœå°‹ï¼š", placeholder="ä¾‹å¦‚ï¼š'supply-chain-dataset', 'customer churn', 'sentiment'")
            st.caption("èªªæ˜ï¼šè¼¸å…¥é—œéµå­—ï¼ˆå¦‚ 'supply-chain-dataset'ï¼‰å¾Œé»æ“Šæœå°‹ï¼Œçµæœæœƒé¡¯ç¤ºåœ¨ä¸‹æ–¹è¡¨æ ¼ã€‚æ”¯æ´å¤šé—œéµå­—æœå°‹ï¼Œä½¿ç”¨ç©ºæ ¼åˆ†éš”ã€‚")
            submit_button = st.form_submit_button(label="æœå°‹")
            st.caption("èªªæ˜ï¼šé»æ“Šæœå°‹å¾Œï¼Œç³»çµ±å°‡å¾ Kaggle æŸ¥è©¢ç¬¦åˆé—œéµå­—çš„è³‡æ–™é›†ã€‚")

        if submit_button and manual_search_term:
            with st.spinner(f"æ­£åœ¨æœå°‹ '{manual_search_term}'..."):
                try:
                    datasets = api.dataset_list(search=manual_search_term)
                    if datasets:
                        dataset_data = [{'Ref': d.ref, 'Title': d.title} for d in datasets]
                        st.session_state.manual_search_df = pd.DataFrame(dataset_data)
                    else:
                        st.warning(f"æ‰¾ä¸åˆ°é—œæ–¼ '{manual_search_term}' çš„è³‡æ–™é›†ã€‚")
                        st.session_state.manual_search_df = pd.DataFrame()
                except Exception as e:
                    st.error(f"æœå°‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        if 'manual_search_df' in st.session_state and not st.session_state.manual_search_df.empty:
            st.subheader("æ‰‹å‹•æœå°‹çµæœ")
            st.dataframe(st.session_state.manual_search_df, use_container_width=True)

    st.markdown("---")
    st.subheader("ğŸ“¥ ä¸‹è¼‰è³‡æ–™é›†")
    dataset_ref_to_download = st.text_input("å¾ä¸Šæ–¹ä»»ä¸€çµæœä¸­è¤‡è£½ Ref è²¼åˆ°æ­¤è™•é€²è¡Œä¸‹è¼‰ï¼š", key="data_ref_unified")
    st.caption("èªªæ˜ï¼šRef æ˜¯è³‡æ–™é›†çš„å”¯ä¸€è­˜åˆ¥ç¢¼ï¼Œæ ¼å¼å¦‚ 'username/dataset-name'ï¼Œå¯å¾ä¸Šæ–¹è¡¨æ ¼è¤‡è£½ã€‚")
    if st.button("ä¸‹è¼‰å®Œæ•´è³‡æ–™é›†", key="download_dataset_button"):
        st.caption("èªªæ˜ï¼šé»æ“Šå¾Œï¼Œè³‡æ–™é›†å°‡ä¸‹è¼‰ä¸¦è§£å£“ç¸®è‡³ 'kaggle_downloads/{Ref}' å­è³‡æ–™å¤¾ã€‚")
        if dataset_ref_to_download:
            base_path = 'kaggle_downloads'
            download_path = os.path.join(base_path, dataset_ref_to_download)  # æ–°å¢ï¼šä½¿ç”¨ Ref ä½œç‚ºå­è³‡æ–™å¤¾åç¨±
            os.makedirs(download_path, exist_ok=True)
            with st.spinner(f"æ­£åœ¨ä¸‹è¼‰ä¸¦è§£å£“ç¸® '{dataset_ref_to_download}' çš„æ‰€æœ‰æª”æ¡ˆ..."):
                try:
                    api.dataset_download_files(dataset_ref_to_download, path=download_path, unzip=True)
                    st.success(f"è³‡æ–™é›† '{dataset_ref_to_download}' å·²æˆåŠŸä¸‹è¼‰ä¸¦è§£å£“ç¸®åˆ° `{download_path}` è³‡æ–™å¤¾ï¼")
                except Exception as e:
                    st.error(f"ä¸‹è¼‰è³‡æ–™é›†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        else:
            st.warning("è«‹å…ˆè¼¸å…¥è¦ä¸‹è¼‰çš„è³‡æ–™é›† Refã€‚")
    pygwalker_page()
    code_finder_page(api)
    
# --- Pygwalker è³‡æ–™æ¢ç´¢ä»‹é¢ ---
def pygwalker_page():
    st.title("ğŸ“Š Pygwalker")
    st.info("è«‹å…ˆä½¿ç”¨å·¦å´çš„ **Kaggle API å·¥å…·** ä¸‹è¼‰ CSV æª”æ¡ˆï¼Œç„¶å¾Œåœ¨æ­¤è™•é¸æ“‡æª”æ¡ˆé€²è¡Œäº’å‹•å¼åˆ†æã€‚")

    download_folder = 'kaggle_downloads'
    try:
        supported_formats = ['*.csv', '*.xlsx']
        files = []
        for fmt in supported_formats:
            files.extend(glob.glob(os.path.join(download_folder, "**", fmt), recursive=True))
    except FileNotFoundError:
        files = []

    if not files:
        st.warning(f"åœ¨ `{download_folder}` è³‡æ–™å¤¾ä¸­æ‰¾ä¸åˆ°ä»»ä½•æ”¯æ´çš„æª”æ¡ˆï¼ˆCSVã€Excelã€JSONï¼‰ã€‚")
        return

    display_files = [os.path.relpath(f, download_folder) for f in files]
    selected_display_file = st.selectbox("é¸æ“‡ä¸€å€‹å·²ä¸‹è¼‰çš„æª”æ¡ˆé€²è¡Œåˆ†æï¼š", display_files)
    st.caption("èªªæ˜ï¼šæ”¯æ´ CSVã€Excelã€JSON æ ¼å¼ã€‚è‹¥æª”æ¡ˆç„¡æ³•è¼‰å…¥ï¼Œè«‹æª¢æŸ¥æ ¼å¼æˆ–ç·¨ç¢¼ã€‚")

    if selected_display_file:
        file_path = os.path.join(download_folder, selected_display_file)
        with st.spinner(f"æ­£åœ¨è®€å– '{selected_display_file}'..."):
            try:
                if file_path.endswith('.csv'):
                    try:
                        df = pd.read_csv(file_path, encoding='utf-8')
                    except UnicodeDecodeError:
                        df = pd.read_csv(file_path, encoding='latin1')
                elif file_path.endswith('.xlsx'):
                    df = pd.read_excel(file_path)
                elif file_path.endswith('.json'):
                    df = pd.read_json(file_path)
                else:
                    st.error("ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼")
                    return
                st.subheader(f"æ­£åœ¨åˆ†æ: `{selected_display_file}`")
                renderer = StreamlitRenderer(df)
                renderer.explorer()
            except Exception as e:
                st.error(f"è¼‰å…¥è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                return

# --- ä¸»ç¨‹å¼åŸ·è¡Œå€å¡Š ---
def main():
    if 'api_authenticated' not in st.session_state:
        st.session_state.api_authenticated = False
    
    api = init_kaggle_api()
    
    if not st.session_state.get('api_authenticated', False):
        st.error("Kaggle API èªè­‰å¤±æ•—ï¼Œè«‹ä¸Šå‚³æ‚¨çš„ kaggle.json æª”æ¡ˆã€‚")
        uploaded_file = st.file_uploader("ä¸Šå‚³ kaggle.json æª”æ¡ˆ", type="json")
        if uploaded_file:
            try:
                # å°‡ä¸Šå‚³æª”æ¡ˆä¿å­˜åˆ°æŒ‡å®šè·¯å¾‘
                local_kaggle_path = "kaggle.json"
                with open(os.path.join(BASE_DIR, local_kaggle_path), 'wb') as f:
                    f.write(uploaded_file.getvalue())
                
                # è®€å– JSON ä¸¦è¨­å®šç’°å¢ƒè®Šæ•¸
                with open(os.path.join(BASE_DIR, local_kaggle_path), 'r') as f:
                    credentials = json.load(f)
                os.environ['KAGGLE_USERNAME'] = credentials['username']
                os.environ['KAGGLE_KEY'] = credentials['key']
                
                # åˆå§‹åŒ– API
                api = init_kaggle_api()
                if api:
                    st.session_state['api_authenticated'] = True
                    st.success("kaggle.json è®€å–æˆåŠŸï¼API å·²èªè­‰ã€‚")
                else:
                    st.error("kaggle.json ç„¡æ•ˆï¼Œèªè­‰å¤±æ•—ã€‚")
            except Exception as e:
                st.error(f"è®€å– kaggle.json æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    if st.session_state.get('api_authenticated', False) and api:
        st.toast("Kaggle API å·²èªè­‰æˆåŠŸï¼")
        main_page(api)

if __name__ == "__main__":
    main()